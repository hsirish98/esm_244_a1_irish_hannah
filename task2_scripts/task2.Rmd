---
title: "California Coast Oxygen Saturation"
author: "Hannah Irish"
date: "2023-01-26"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=TRUE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(janitor)
library(AICcmodavg)

```

<center> <h1>**California Coast Oxygen Saturation**</h1> </center>


## **Introduction**

The data in this project is from the California Cooperative Oceanic Fisheries Investigations (CalCOFI) 70+ year time series measuring water quality factors off the coast of California including salinity, temperature, oxygen, phosphate and later silicate, nitritie, chlorophyll, etc.


## **Methods**

This code reads in the data using read_csv():
```{r, warning=FALSE, message=FALSE}

sea_samples <- read_csv(here("data_task2", "calcofi_seawater_samples.csv"))
```

This code creates models for multiple linear regression. Model 1 models O2 Saturation by temperature in Celcius, salinity, and phosphate concentration. Model 2 models O2 saturation by all of those factors as well as depth in meters. Model 3 tests whether a simpler model is best, modeling O2 saturation by only temperature in Celcius and depth in meters:
```{r}

model_1 <- lm(o2sat ~ t_deg_c + salinity + po4u_m, data=sea_samples)
form1 <- o2sat ~ t_deg_c + salinity + po4u_m

model_2 <- lm(o2sat ~ t_deg_c + salinity + po4u_m + depth_m, data=sea_samples)
form2 <- o2sat ~ t_deg_c + salinity + po4u_m + depth_m

model_3 <- lm(o2sat ~ t_deg_c + depth_m + salinity, data = sea_samples)
form3 <- o2sat ~ t_deg_c + depth_m
```

## **Model Selection**

This code calculates AIC and BIC for models to give me an indication of which might be better:
```{r, warning=FALSE, message=FALSE, results=FALSE}

aictab(list(model_1, model_2, model_3))
bictab(list(model_1, model_2, model_3))

```


### **10-Fold (by 10-Fold) Cross-Validation**

I investigate even futher and this code creates function to calculate Root Mean Square Error (rmse) as that will be our scoring method for model selection:

```{r}
rmse_calc <- function(actual, predicted) {
  rmse <- (actual - predicted)^2 %>%
    mean() %>%
    sqrt() 
  return(rmse)
}
```

This code creates a matrix so I can do my nested for loop 10 more times cross validation with a different vector every time:
```{r}

iterations_n  <- 10

m_vector <- c(1,2,3,4,5,6,7,8,9,10,2,3,4,5,6,7,8,9,10,1,3,4,5,6,7,8,9,10,1,2,4,5,6,7,8,9,10,1,2,3,5,6,7,8,9,10,1,2,3,4,6,7,8,9,10,1,2,3,4,5,7,8,9,10,1,2,3,4,5,6,8,9,10,1,2,3,4,5,6,7,9,10,1,2,3,4,5,6,7,8,10,1,2,3,4,5,6,7,8,9)
my_matrix <- matrix(m_vector, nrow=iterations_n, ncol=iterations_n)


```

This code chunk calculates RMSE averages for both models by using 10-fold by 10-fold cross validation to see which model is able to predict the data with minimal errors:

```{r, results=FALSE}

rmse_results <- data.frame() ## create a data frame to add these

iterations_n  <- 10
folds <- 10

set.seed(43)

for(j in 1:iterations_n) {
  
  iter_vector <- rep(my_matrix[j, ], length.out = nrow(sea_samples)) ##choose a vector (1:10 but in a different order to sample from.
  
  sea_sample_kfold <- sea_samples %>%
  mutate(fold = sample(iter_vector, size=n(), replace=FALSE)) ##set the folds based on chosen vector
  
 # print(head(sea_sample_kfold$fold)) ##This is to test that it's truly giving me a different set every time
  
for(i in 1:folds) {
  
  testing_df <- sea_sample_kfold %>%
    filter(fold==i) 
  training_df <- sea_sample_kfold %>%
    filter(fold!=i)
    
  kfold_mdl1 <- lm(form1, data=training_df)
  kfold_mdl2 <- lm(form2, data=training_df)
  kfold_mdl3 <- lm(form3, data=training_df)
  
  predictions_df <- testing_df %>%
    mutate(mdl1 = predict(kfold_mdl1, .),
           mdl2 = predict(kfold_mdl2, .),
           mdl3 = predict(kfold_mdl3, .))
  
  iterative_rmse <- predictions_df %>%
    summarize(rmse_m1 = rmse_calc(mdl1, o2sat),
              rmse_m2 = rmse_calc(mdl2, o2sat),
              rmse_m3 = rmse_calc(mdl3, o2sat))
  
  rmse_results <- bind_rows(rmse_results, iterative_rmse)
 }
}

rmse_results %>%
  summarize(mean_rmse_mdl1 = mean(rmse_m1), mean_rmse_mdl2 = mean(rmse_m2), mean_rmse_mdl3 = mean(rmse_m3))

```

## **Results**
My results from the AIC. BIC, and from comparing RMSE to find the minimum indicate that model 2 is the *slightly* better model. It minimizes AIC, BIC *and* RMSE, as you can see from the following table:

```{r}
Model <- c("Model 1", "Model 2", "Model 3")
AIC<-c(round(AIC(model_1),1), round(AIC(model_2),1), round(AIC(model_3),1))
BIC<-c(round(BIC(model_1),1), round(BIC(model_2),1), round(BIC(model_3),1))
RMSE<-c(round(mean(rmse_results$rmse_m1),2),round(mean(rmse_results$rmse_m2),2),round(mean(rmse_results$rmse_m3),2))

my_table <- data.frame(Model, AIC, BIC, RMSE)

knitr::kable(my_table)
```

The lowest values (AIC `r round(AIC(model_2),1)`, BIC `r round(BIC(model_2),1)`, and mean RMSE `r round(mean(rmse_results$rmse_m3),2)` all belong to Model 2

**Selected Model**: Model 2: Oxygen Saturation is a function of water temperature, salinity, phosphate concentration, and depth.


This code trains the final model on the entire data set:
```{r}
final_model <- lm(form2, data=sea_samples)
```

Final model for O2 saturation:

`r equatiomatic::extract_eq(final_model, wrap = TRUE)`

## **References**

CalCOFI data are available for use without restriction. Data downloaded from https://calcofi.org/ccdata.html.  Accessed 1/10/2022.